# -*- coding: utf-8 -*-
from typing import Dict, List, Any
from langchain_openai import ChatOpenAI
from langchain_classic.retrievers.multi_query import MultiQueryRetriever
from langchain_classic.chains.combine_documents import create_stuff_documents_chain
from langchain_classic.chains import create_retrieval_chain
from langchain_core.prompts import ChatPromptTemplate, PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from langchain_community.cache import InMemoryCache
from langchain_core.globals import set_llm_cache
from config import Config
from modules.prompts import RAGPrompts
from pydantic import SecretStr
from loguru import logger

class RAGEngine:
    def __init__(self, vector_store):
        self.vector_store = vector_store
        # è®¾ç½®ç¼“å­˜
        set_llm_cache(InMemoryCache())
        
        # åˆå§‹åŒ–å„åŠŸèƒ½æ¨¡å‹
        # 1. æŸ¥è¯¢å¤„ç†æ¨¡å‹
        query_rewrite_model_api_key = Config.QUERY_REWRITE_MODEL_API_KEY
        self.query_rewrite_llm = ChatOpenAI(
            model=Config.QUERY_REWRITE_MODEL_NAME,
            temperature=Config.QUERY_REWRITE_MODEL_TEMPERATURE,
            api_key=SecretStr(query_rewrite_model_api_key) if query_rewrite_model_api_key else None,
            base_url=Config.QUERY_REWRITE_MODEL_BASE_URL
        )
        logger.info(f"æŸ¥è¯¢æ”¹å†™æ¨¡å‹:{Config.QUERY_REWRITE_MODEL_NAME}")
        # 2. å›ç­”ç”Ÿæˆæ¨¡å‹
        response_model_api_key = Config.RESPONSE_MODEL_API_KEY
        self.response_llm = ChatOpenAI(
            model=Config.RESPONSE_MODEL_NAME,
            temperature=Config.RESPONSE_MODEL_TEMPERATURE,
            api_key=SecretStr(response_model_api_key) if response_model_api_key else None,
            base_url=Config.RESPONSE_MODEL_BASE_URL
        )
        logger.info(f"å›ç­”ç”Ÿæˆæ¨¡å‹:{Config.RESPONSE_MODEL_NAME}")

        # 3. è§£ææ¨¡å‹å›ç­”ä¸­çš„Jsonç»“æ„
        self.ner_parser = JsonOutputParser()

    def _extract_entities(self, query: str) -> Dict[str, List[str]]:
        """
        åˆ©ç”¨ LLM ä» Query ä¸­æå–å®ä½“ï¼Œç”¨äºæ„å»º Filter
        """
        prompt = PromptTemplate(
            template=RAGPrompts.QUERY_NER_TEMPLATE,
            input_variables=["text"]
        )
        # æ‰“é€š Prompt -> LLM -> Parser æµç¨‹
        chain = prompt | self.query_rewrite_llm | self.ner_parser
        try:
            logger.info("ğŸ” æ­£åœ¨åˆ†ææŸ¥è¯¢é—®é¢˜ä¸­çš„å®ä½“...")
            result = chain.invoke({"text": query})
            # ç®€å•æ¸…æ´—ï¼Œç¡®ä¿ key å­˜åœ¨
            cleaned_result = {k: result.get(k, []) for k in ["people", "locations", "times"]}
            logger.info(f"æå–å®ä½“ç»“æœ: {cleaned_result}, ç³»ç»Ÿå°†ä½¿ç”¨è¯¥ç»“æœè¿›è¡Œå®ä½“è¿‡æ»¤")
            return cleaned_result
        except Exception as e:
            logger.warning(f"å®ä½“æå–å¤±è´¥ï¼Œå°†é™çº§ä¸ºæ— è¿‡æ»¤æ£€ç´¢: {e}")
            return {}

    def _create_dynamic_filter(self, entities: Dict[str, List[str]]):
            """
            æ„å»º FAISS è¿‡æ»¤é€»è¾‘
            """
            if not any(entities.values()):
                logger.error("æœªæå–åˆ°ä»»ä½•å®ä½“ï¼Œæ— æ³•æ„å»ºåŠ¨æ€è¿‡æ»¤å™¨ã€‚")
                return None

            # ä¸€ä¸ªæ¥æ”¶å¾…è¿‡æ»¤metadataå‚æ•°ï¼Œç›¸å½“äºä¹¦å†™è¿‡æ»¤æˆåŠŸä¸å¦çš„é€»è¾‘
            def metadata_filter(metadata: Dict[str, Any]) -> bool:
                # 1. æ£€æŸ¥æ–‡æ¡£æ˜¯å¦æœ‰ NER æ•°æ®
                doc_ner = metadata.get("ner", {})
                if not doc_ner:
                    return False
                
                # 2. é€»è¾‘åŒ¹é…ï¼šåªè¦ Query é‡Œçš„ä»»æ„ä¸€ä¸ªå®ä½“å‡ºç°åœ¨æ–‡æ¡£çš„ NER åˆ—è¡¨ä¸­ï¼Œå³è§†ä¸ºåŒ¹é…
                # è¿™é‡Œé‡‡ç”¨â€œå®½æ¾åŒ¹é…â€ç­–ç•¥ï¼Œä¹Ÿå¯ä»¥æ”¹ä¸ºâ€œä¸¥æ ¼åŒ¹é…â€
                for label, values in entities.items():
                    if not values:
                        continue
                    doc_values = doc_ner.get(label, [])
                    # æ£€æŸ¥ä¸¤ä¸ªåˆ—è¡¨æ˜¯å¦æœ‰äº¤é›†
                    if set(values) & set(doc_values):
                        return True
                
                return False
                
            return metadata_filter

    def _get_retriever(self, search_type: str = Config.SEARCH_TYPE, use_ner_filter:bool = False):
        """
        æ„å»º MultiQuery æ£€ç´¢å™¨
        Args:
            search_type: æ£€ç´¢ç±»å‹ï¼Œé»˜è®¤ä¸º "mmr",è¿˜å¯é€‰ "similarity"
            use_ner_filter: æ˜¯å¦å¼€å¯å®ä½“è¿‡æ»¤
        """
        base_kwargs = {
            "k": Config.RETRIEVER_K,
            "fetch_k": Config.RETRIEVER_FETCH_K
        }

        # å¦‚æœä¸ä½¿ç”¨è¿‡æ»¤ï¼Œç›´æ¥è¿”å›æ ‡å‡†çš„ MultiQueryRetriever
        if not use_ner_filter:
            base_retriever = self.vector_store.as_retriever(
                search_type=search_type,
                search_kwargs=base_kwargs
            )
            return self._wrap_multi_query(base_retriever)
        
        # è‹¥å¼€å¯è¿‡æ»¤ï¼Œéœ€è¦æ„å»ºå¸¦è¿‡æ»¤çš„åŠ¨æ€æ£€ç´¢å™¨
        # ä½¿ç”¨ RunnableLambda åŒ…è£…æ£€ç´¢è¿‡ç¨‹ï¼Œä½¿å…¶å¯ä»¥è®¿é—® runtime çš„è¾“å…¥(query)
        # def retrieval_func(input_dict: Dict[str, Any]):
        #     question = input_dict["input"]
        #     # 1. æå–å®ä½“
        #     entities = self._extract_entities(question)
        #     # 2. æ„å»ºè¿‡æ»¤å™¨
        #     faiss_filter = self._create_dynamic_filter(entities)
        #     # 3. åŠ¨æ€é…ç½® Retriever
        #     # æ³¨æ„ï¼šFAISS çš„ as_retriever ç”Ÿæˆçš„å¯¹è±¡å¦‚æœå†æ¬¡ä¿®æ”¹ search_kwargs å¯èƒ½ä¼šæœ‰æ·±æ‹·è´é—®é¢˜
        #     # æ‰€ä»¥æˆ‘ä»¬åœ¨è¿™ä¸€æ­¥åŠ¨æ€ç”Ÿæˆä¸€ä¸ªæ–°çš„ retriever
        #     current_kwargs = base_kwargs.copy()
        #     if faiss_filter:
        #         current_kwargs["filter"] = faiss_filter  # type: ignore
        #         logger.info("âœ… å·²åº”ç”¨å®ä½“è¿‡æ»¤å™¨")
        #     else:
        #         logger.info("âš ï¸ æœªæå–åˆ°æœ‰æ•ˆå®ä½“ï¼Œè·³è¿‡è¿‡æ»¤")

        #     dynamic_retriever = self.vector_store.as_retriever(
        #         search_type=search_type,
        #         search_kwargs=current_kwargs
        #     )
            
        #     # 4. æ‰§è¡Œæ£€ç´¢ (è¿™é‡Œä¾ç„¶å¯ä»¥å¥—ç”¨ MultiQueryï¼Œä½†ä¸ºäº†æ€§èƒ½å’Œé€»è¾‘æ¸…æ™°ï¼Œå»ºè®®å…ˆå•æ¬¡æ£€ç´¢)
        #     # å¦‚æœéå¸¸éœ€è¦ MultiQuery + Filterï¼Œéœ€è¦å°† Filter ä¼ é€’ç»™ MultiQuery å†…éƒ¨çš„ retriever
        #     # ç®€å•èµ·è§ï¼Œè¿™é‡Œæ¼”ç¤ºç›´æ¥æ£€ç´¢
        #     return dynamic_retriever.invoke(question)
        
        # # RunnableLambdaå°†ä¸€èˆ¬Pythonå‡½æ•°å°è£…ä¸ºå¯é›†æˆè¿›Chainçš„ä¸“ç”¨ç±»
        # # å¯ä»¥ä½¿ç”¨LangChainä¸­çš„.invoke()ç­‰æ–¹æ³•ï¼Œç”¨ | ç¬¦å·ä¸å…¶ä»–ç®¡é“æ¥é€š
        # return RunnableLambda(retrieval_func)
    
        # --- æ ¸å¿ƒé€»è¾‘ï¼šå¯¹æ¯ä¸€æ¡æ”¹å†™åçš„æŸ¥è¯¢è¿›è¡Œ NER æå– ---
        def multi_query_ner_flow(input_dict: Dict[str, Any]):
            original_query = input_dict["input"]
            
            # 1. æ˜¾å¼è°ƒç”¨æ”¹å†™é€»è¾‘ï¼Œè·å–å¤šä¸ªå­æŸ¥è¯¢
            # ä½¿ç”¨æˆ‘ä»¬å®šä¹‰çš„ query_rewrite_llm å’Œ prompt
            rewrite_prompt = PromptTemplate(
                template=RAGPrompts.QUERY_REWRITE_TEMPLATE,
                input_variables=["question"]
            )
            # è¿™é‡Œæˆ‘ä»¬æ‰‹åŠ¨é€šè¿‡ LLM è·å–æ”¹å†™åˆ—è¡¨ï¼ˆå‡è®¾ Prompt è¦æ±‚æ¢è¡Œåˆ†éš”ï¼‰
            rewrite_chain = rewrite_prompt | self.query_rewrite_llm
            rewrite_output = rewrite_chain.invoke({"question": original_query})
            
            # è§£ææ”¹å†™åçš„é—®é¢˜åˆ—è¡¨ (å¤„ç†å­—ç¬¦ä¸²ï¼Œå»é™¤ç©ºè¡Œ)
            # å»ºè®®åœ¨ Prompt ä¸­æ˜ç¡®è¦æ±‚è¾“å‡ºæ ¼å¼ï¼Œæ­¤å¤„å‡è®¾æŒ‰è¡Œåˆ†éš”
            rewritten_queries = [original_query]  # æ€»æ˜¯åŒ…å«åŸå§‹é—®é¢˜
            try:
                if hasattr(rewrite_output, 'content'):
                    lines = rewrite_output.content.strip().split("\n")
                    rewritten_queries.extend([line.strip() for line in lines if line.strip()])
            except Exception as e:
                logger.warning(f"æ”¹å†™æ¨¡å—å‡ºç°å¼‚å¸¸,è¯·æ’æŸ¥é—®é¢˜,æš‚é€€å›è‡³åŸå›ç­”æŸ¥è¯¢")
                rewritten_queries.extend(original_query)
            
            logger.info(f"ğŸ”„ æœ€ç»ˆå…±æœ‰ {len(rewritten_queries)} æ¡æŸ¥è¯¢è¯­å¥,åˆ†åˆ«ä¸º")
            for idx, query in enumerate(rewritten_queries):
                logger.info(f"ç¬¬{idx+1}æ¡æŸ¥è¯¢è¯­å¥ï¼š{query}")

            # 2. å¯¹æ¯ä¸€æ¡æŸ¥è¯¢æ‰§è¡Œï¼šæå–å®ä½“ -> æ„å»ºè¿‡æ»¤ -> æ‰§è¡Œæ£€ç´¢
            all_documents = []
            seen_doc_ids = set()

            for idx, q in enumerate(rewritten_queries):
                logger.info(f"å¤„ç†å­æŸ¥è¯¢ [{idx+1}]: {q}")
                
                # ä¸ºå½“å‰å­æŸ¥è¯¢æå–å®ä½“
                entities = self._extract_entities(q)
                faiss_filter = self._create_dynamic_filter(entities)
                
                # é…ç½®å¸¦è¿‡æ»¤çš„æ£€ç´¢å‚æ•°
                current_kwargs = base_kwargs.copy()
                if faiss_filter:
                    current_kwargs["filter"] = faiss_filter
                
                # æ‰§è¡Œå•æ¬¡æ£€ç´¢
                # ç›´æ¥è°ƒç”¨ vector_store çš„æ£€ç´¢æ–¹æ³•ï¼Œæ•ˆç‡æ›´é«˜
                if search_type == "mmr":
                    docs = self.vector_store.max_marginal_relevance_search(
                        q, **current_kwargs
                    )
                else:
                    docs = self.vector_store.similarity_search(
                        q, **current_kwargs
                    )
                
                # 3. åˆå¹¶ç»“æœå¹¶å»é‡ï¼ˆåŸºäºæ–‡æ¡£å†…å®¹æˆ– IDï¼‰
                for doc in docs:
                    # ä½¿ç”¨ page_content çš„ hash æˆ– metadata ä¸­çš„ id ä½œä¸ºå»é‡é”®
                    doc_id = hash(doc.page_content) 
                    if doc_id not in seen_doc_ids:
                        all_documents.append(doc)
                        seen_doc_ids.add(doc_id)

            logger.info(f"âœ… æœ€ç»ˆå¬å›å»é‡æ–‡æ¡£æ•°: {len(all_documents)}")
            return all_documents

        return RunnableLambda(multi_query_ner_flow)

    def _wrap_multi_query(self, base_retriever):
        """
        å°è£… MultiQuery é€»è¾‘ï¼Œå³ä¸ä½¿ç”¨NERè¿‡æ»¤
        """
        query_prompt = PromptTemplate(
            input_variables=["question"],
            template=RAGPrompts.QUERY_REWRITE_TEMPLATE
        )
        logger.info("æ„å»º MultiQueryRetriever...")
        return MultiQueryRetriever.from_llm(
            retriever=base_retriever,
            llm=self.query_rewrite_llm,
            prompt=query_prompt,
        )


    # def build_chain(self, use_ner_filter:bool = False):
        
    #     """
    #     æ„å»ºå®Œæ•´çš„ RAG Chainï¼ŒåŒ…å«æ£€ç´¢å™¨ã€æ–‡æ¡£æ¥å£å’Œå›ç­”ç”Ÿæˆé“¾
    #     """
        
    #     # å®šä¹‰å¥½é—®ç­”æ¨¡å‹prompt
    #     qa_prompt = ChatPromptTemplate.from_messages([
    #         ("system", RAGPrompts.QA_SYSTEM_PROMPT),
    #         ("human", "{input}"),
    #     ])

    #     # è§„èŒƒåŒ–å‚è€ƒæ–‡æ¡£æ ¼å¼
    #     document_prompt = PromptTemplate(
    #         input_variables=["page_content", "index"], 
    #         template="ã€æ–‡æ¡£ç¼–å·:{index}ã€‘\nå†…å®¹:{page_content}"
    #     )

    #     # åœ¨æ„å»º combine_docs_chain æ—¶ï¼Œéœ€è¦å¯¹ä¼ å…¥çš„ docs è¿›è¡Œé¢„å¤„ç†ï¼ˆå¢åŠ  index å­—æ®µï¼‰
    #     # è¿™æ˜¯ä¸€ä¸ªç®€å•çš„ RunnableLambda å¤„ç†é€»è¾‘
    #     def format_docs_with_index(input_dict):
    #         docs = input_dict["context"]
    #         for i, doc in enumerate(docs):
    #             doc.metadata["index"] = i + 1
    #         return input_dict

        
    #     # 1. å°†æ–‡æ¡£æ¥å£æ•´åˆè¿›å›ç­”ç”Ÿæˆé“¾
    #     combine_docs_chain = create_stuff_documents_chain(self.response_llm, qa_prompt,document_prompt=document_prompt)
    #     # 2. åˆå§‹åŒ–æ£€ç´¢å™¨
    #     retriever = self._get_retriever(use_ner_filter=use_ner_filter)
    #     # 3. æœ€ç»ˆ RAG é“¾
    #     return create_retrieval_chain(retriever, combine_docs_chain)

    def build_chain(self, use_ner_filter: bool = False):
        
        """
        æ„å»ºå®Œæ•´çš„ RAG Chainï¼ŒåŒ…å«åŠ¨æ€ç´¢å¼•é¢„å¤„ç†
        """
        # 1. å®šä¹‰é—®ç­”æç¤ºè¯
        qa_prompt = ChatPromptTemplate.from_messages([
            ("system", RAGPrompts.QA_SYSTEM_PROMPT),
            ("human", "{input}"),
        ])

        # 2. å®šä¹‰å•ä¸ªæ–‡æ¡£åœ¨ Prompt ä¸­çš„å±•ç°æ ¼å¼
        # è¿™é‡Œçš„ index å¿…é¡»å¯¹åº” metadata ä¸­çš„é”®
        document_prompt = PromptTemplate(
            input_variables=["page_content", "index"], 
            template="ã€æ–‡æ¡£ç¼–å·:{index}ã€‘\nå†…å®¹:{page_content}"
        )

        # 3. æ„å»ºåŸºç¡€çš„æ–‡æ¡£æ•´åˆé“¾
        combine_docs_chain = create_stuff_documents_chain(
            self.response_llm, 
            qa_prompt, 
            document_prompt=document_prompt
        )

        # 4. åˆå§‹åŒ–æ£€ç´¢å™¨ï¼ˆæ ¹æ®ä½ çš„é€»è¾‘å¯èƒ½æ˜¯ RunnableLambda æˆ– MultiQueryï¼‰
        retriever = self._get_retriever(use_ner_filter=use_ner_filter)

        # 5. å®šä¹‰æ–‡æ¡£ç´¢å¼•é¢„å¤„ç†é€»è¾‘ (æ ¸å¿ƒä¿®æ”¹ç‚¹)
        def add_index_to_docs(input_dict):
            # create_retrieval_chain è¿è¡Œåˆ°è¿™ä¸€æ­¥æ—¶ï¼Œcontext é‡Œå·²ç»æ˜¯ List[Document]
            docs = input_dict["context"]
            for i, doc in enumerate(docs):
                # å°†ç´¢å¼•å­˜å…¥ metadataï¼Œè¿™æ · document_prompt æ‰èƒ½è¯»å–åˆ°
                doc.metadata["index"] = i + 1
            return input_dict

        # 6. ç»„è£…æœ€ç»ˆé“¾æ¡
        # é€»è¾‘ï¼šæ£€ç´¢ -> æ·»åŠ ç´¢å¼• -> é€å…¥æ–‡æ¡£æ•´åˆé“¾
        # æˆ‘ä»¬ä½¿ç”¨ create_retrieval_chain ä½œä¸ºåŸºç¡€ï¼Œä½†é€šè¿‡ | æ’å…¥æ‹¦æˆªé€»è¾‘
        base_chain = create_retrieval_chain(retriever, combine_docs_chain)
        
        # ä½¿ç”¨ RunnableLambda åœ¨æ•°æ®æµä¸­è¿›è¡Œâ€œæ‹¦æˆªå¹¶ä¿®æ”¹â€
        final_chain = base_chain | RunnableLambda(add_index_to_docs) | combine_docs_chain
        
        # æ³¨æ„ï¼šcreate_retrieval_chain æœ¬èº«è¿”å›çš„æ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰ä¿¡æ¯çš„å­—å…¸
        # ä¸ºäº†ä¿æŒæ¥å£ç»Ÿä¸€ï¼Œæœ€ä¼˜é›…çš„å†™æ³•æ˜¯æ‰‹åŠ¨æ„å»ºè¿™ä¸ªæµï¼š
        
        final_rag_chain = (
            # ç¬¬ä¸€æ­¥ï¼šæ£€ç´¢å¹¶ä¿ç•™åŸå§‹è¾“å…¥
            RunnablePassthrough.assign(context=retriever)
            # ç¬¬äºŒæ­¥ï¼šç»™æ£€ç´¢åˆ°çš„ context æ·»åŠ  index å­—æ®µ
            | RunnableLambda(add_index_to_docs)
            # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆå›ç­”å¹¶ä¿ç•™ context
            | RunnablePassthrough.assign(answer=combine_docs_chain)
        )

        return final_rag_chain